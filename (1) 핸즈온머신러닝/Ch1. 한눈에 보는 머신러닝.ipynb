{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 머신러닝 애플리케이션 : 스팸필터(1990년대)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.1 머신러닝이란?\n",
    "\n",
    "# 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학.\n",
    "\n",
    "# Arthur Samuel, 1959, \"명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야\"\n",
    "\n",
    "# Tom Mitchell, 1977, \"어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면,\n",
    "#                       이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.\"\n",
    "# ex) 작업 T : 새로운 메일이 스팸인지 구분하는 것\n",
    "#     성능 P : 정확히 분류된 메일의 비율 (정확도)\n",
    "#     경험 E : training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2 왜 머신러닝을 사용하는가?\n",
    "\n",
    "# 전통방법 : 스팸에 어떤 단어들이 많이 사용되는지 살펴본 후, 이 패턴을 감지하는 알고리즘을 작성하여 스팸으로 분류\n",
    "# 머신러닝 : 일반 메일에 비해 스팸에 자주 나타나는 패턴을 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.3 머신러닝 시스템의 종류\n",
    "\n",
    "# (1) 지도학습과 비지도 학습\n",
    "\n",
    "# 지도학습 : training data에 label이라는 원하는 답이 포함된다\n",
    "# ex) k-nearest neighbors, linear regression, logistic regression, svm, decision tree, random forests, neural networks\n",
    "\n",
    "# 비지도학습 : training data에 label이 없음\n",
    "# ex) clustering, visualization, dimensionality reduction, association rule learning\n",
    "\n",
    "# 준지도학습 : 레이블이 일부만 있는 데이터를 다루는 알고리즘\n",
    "# 대부분의 준지도학습은 지도학습과 비지도학습의 조합으로 이루어져 있다.\n",
    "\n",
    "# 강화학습 : 환경을 관찰해서 행동을 실행하고 그 결과로 보상 또는 벌점을 받는다. \n",
    "#            시간이 지나면서 가장 큰 보상을 얻기 위해 policy라고 부르는 최상의 전략을 스스로 학습한다.\n",
    "\n",
    "\n",
    "# (2) 배치학습과 온라인 학습 - 입력 데이터의 stream으로부터 점진적으로 학습할 수 있는지 여부에 따라\n",
    "\n",
    "# 배치학습 : 시스템이 점진적으로 학습할 수 없음. 가용한 데이터를 모두 사용해 훈련시켜야 한다.\n",
    "# 온라인학습 : 데이터를 순차적으로 한 개씩 또는 미니배치 단위로 주입하여 시스템을 훈련시킨다.\n",
    "\n",
    "\n",
    "# (3) 사례기반 학습과 모델기반 학습 - 어떻게 일반화되는가에 다른 분류\n",
    "\n",
    "# instance-based learning : 시스템이 사례를 기억함으로써 학습, 그리고 유사도 측정을 사용해 새로운 데이터에 일반화한다.\n",
    "# model-based learning : 샘플들의 모델을 만들어 예측에 사용하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.4 머신러닝의 주요 도전과제\n",
    "\n",
    "# (1) 충분하지 않은 양의 training data\n",
    "# (2) 대표성 없는 training data\n",
    "# (3) 낮은 품질의 data\n",
    "# (4) 관련 없는 특성 : 훈련에 사용할 좋은 특성을 찾는것(특성 공학)이 필요\n",
    "# (5) 훈련 데이터 overfitting => regularization 강화 등\n",
    "# (6) 훈련 데이터 underfitting => regularization 약화 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.5 테스트와 검증\n",
    "\n",
    "# 모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해 보는 것.\n",
    "# 새로운 샘플에 대한 오류 비율을 일반화 오차(generalization error)또는 out-of-sample error라고 한다.\n",
    "# 하지만, 일반화 오차를 테스트 세트에서 여러번 측정하는 것도 문제가 됨. (이를 학습하기 때문)\n",
    "# 이 문제에 대한 일반적인 해결방법은 검증세트(validation set)\n",
    "# training set을 사용해 다양한 초모수로 여러 모델을 훈련시키고, validation set에서 최상의 성능을 내는 모델과 초모수를 선택한다.\n",
    "# 만족스러운 모델을 찾으면 일반화 오차의 추정값을 얻기 위해 test set으로 단 한 번의 최종 테스트를 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
